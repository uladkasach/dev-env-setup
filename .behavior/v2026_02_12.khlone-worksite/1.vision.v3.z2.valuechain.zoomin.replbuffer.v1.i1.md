# khlone: replbuffer vision

> buffer the repl, tame the chaos

---

## the problem

frontier repl tuis (claude code, opencode, etc) are:

- **resource hungry** — claude code consumes as much as vscode
- **unstable** — new defects every day, crashes mid-task
- **unresponsive** — input lags, keystrokes buffer, ui freezes
- **blocks you** — when the repl hangs, you wait

you paid for those tokens. you shouldn't lose work because the tui crashed.

---

## the solution: replbuffer

khlone sits between you and the repl. it:

1. **buffers your input** — type commands even when repl is busy
2. **queues dispatches** — stack up tasks, they execute in order
3. **runs headless** — repl runs without ui overhead by default
4. **streams output** — filtered view shows progress without the noise
5. **enables attach** — drop into raw repl session when you need it
6. **survives crashes** — if repl dies, khlone restarts it, resumes queue

```
┌─────────────────────────────────────────────────────────┐
│                     khlone replbuffer                   │
├─────────────────────────────────────────────────────────┤
│                                                         │
│   YOU ──► khlone tui ──► dispatch queue ──► repl       │
│              │                                 │        │
│              │ (instant)         (when ready)  │        │
│              ▼                                 ▼        │
│         input buffer              claude-code (headless)│
│              │                                 │        │
│              │                                 │        │
│              ▼                                 ▼        │
│         filtered output ◄──────────── raw stream       │
│                                                         │
│   attach mode: bypass buffer, direct repl access       │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

---

## the outcome world

### before

- launch claude code, wait for it to load (10+ seconds)
- type a task, ui freezes while it thinks
- try to type next thought — keystrokes lag or get lost
- claude code crashes mid-task — lose context, restart, re-explain
- laptop fans spin, terminal becomes unresponsive
- switch to another terminal — same sluggishness
- "let me close some stuff" becomes hourly ritual
- work lost when repl hangs and you force-quit

### after

- `khlone` launches instantly — it's just a tui, no ai loaded yet
- type your dispatch — it queues immediately, 0ms latency
- queue more tasks while first one runs — they stack up
- repl runs headless in background — minimal resource draw
- filtered output shows progress — no wall of text
- repl crashes? khlone restarts it, replays queue position
- need raw access? `khlone attach` drops you in
- laptop stays cool, terminal stays responsive
- work survives crashes — queue persists, context preserved

### the "aha" moment

you're deep in a feature. you dispatch "refactor the auth module" and immediately think of three more tasks. you type them all — `dispatch "add tests"`, `dispatch "update docs"`, `dispatch "fix the lint errors"`. they queue up. you walk away to get coffee. when you return, the first two are done, third is in progress. the repl crashed once on "add tests" — you didn't notice because khlone restarted it and continued. your laptop never broke a sweat.

---

## user experience

### usecase 1: basic dispatch flow

**goal**: send tasks to a clone without wait

**timeline**:
1. `khlone` — launches tui (instant, no repl loaded yet)
2. `khlone dispatch "implement user auth"` — queues task
3. khlone spawns repl in headless mode, feeds task
4. you see filtered progress in tui
5. dispatch more tasks — they queue behind current
6. `khlone attach` — drop into raw repl when needed
7. `ctrl+d` — detach back to filtered view

**contract**:
```sh
# launch khlone tui
$ khlone
khlone v0.1 — replbuffer mode
clone: mechanic.1 (claude-code, headless)
status: idle
queue: empty

# dispatch a task (instant return)
$ khlone dispatch "implement jwt validation"
✓ queued: implement jwt validation
queue: 1 task

# dispatch more while first runs
$ khlone dispatch "add unit tests for jwt"
✓ queued: add unit tests for jwt
queue: 2 tasks (1 active, 1 queued)

$ khlone dispatch "update readme with auth docs"
✓ queued: update readme with auth docs
queue: 3 tasks (1 active, 2 queued)

# check status
$ khlone status
clone: mechanic.1 (claude-code, headless)
status: active (47%)
current: implement jwt validation
queue: 2 tasks

# watch filtered progress
$ khlone watch
[mechanic.1] implement jwt validation (47%)
  ├─ created src/auth/jwt.ts
  ├─ created src/auth/jwt.test.ts
  └─ active: implement verify function...

# attach to raw repl
$ khlone attach
[attached to mechanic.1 — claude-code session]
# ... raw repl output ...
# ctrl+d to detach

# detach back to filtered
^D
[detached from mechanic.1]
```

### usecase 2: crash recovery

**goal**: survive repl crashes without lost work

**timeline**:
1. dispatch task, repl starts
2. repl crashes mid-task
3. khlone detects crash, restarts repl
4. khlone resumes from last checkpoint
5. task completes, queue continues

**contract**:
```sh
$ khlone status
clone: mechanic.1 (claude-code, headless)
status: active (67%)
current: refactor auth module

# repl crashes
$ khlone status
clone: mechanic.1 (claude-code, headless)
status: restarted (crash detected, resumed from checkpoint)
current: refactor auth module (67%)
queue: 2 tasks

# automatic recovery — you didn't have to do a task
```

### usecase 3: queue management

**goal**: manage the task queue

**contract**:
```sh
# view queue
$ khlone queue
1. [active 67%] refactor auth module
2. [queued] add integration tests
3. [queued] update api docs
4. [queued] fix lint errors

# add to front of queue (priority)
$ khlone dispatch "hotfix: fix prod bug" --priority
✓ queued at position 2 (after current)

# remove from queue
$ khlone queue rm 4
✓ removed: fix lint errors

# clear queue (keep current)
$ khlone queue clear
✓ cleared 2 queued tasks (kept active task)

# pause queue (finish current, hold rest)
$ khlone queue pause
✓ queue paused after current task

# resume queue
$ khlone queue resume
✓ queue resumed
```

### usecase 4: multiple clones (local)

**goal**: run multiple clones locally via replbuffer

even without zones, you can run multiple clones locally — each gets its own buffered repl.

**contract**:
```sh
# start with default clone
$ khlone
clone: mechanic.1 (claude-code, headless)

# add another clone
$ khlone crew add --role mechanic --brain claude
✓ spawned mechanic.2 (claude-code, headless)

# add a codex clone
$ khlone crew add --role mechanic --brain codex
✓ spawned mechanic.3 (opencode, headless)

# view crew
$ khlone crew
role          brain       repl         status      queue
─────────────────────────────────────────────────────────
mechanic.1    claude      claude-code  active      3 tasks
mechanic.2    claude      claude-code  idle        0 tasks
mechanic.3    codex       opencode     active      1 task

# dispatch to specific clone
$ khlone dispatch "optimize the query" --to mechanic.2
✓ queued to mechanic.2

# attach to specific clone
$ khlone attach mechanic.3
[attached to mechanic.3 — opencode session]
```

---

## architecture

```
┌─────────────────────────────────────────────────────────────────┐
│                     khlone (local replbuffer mode)              │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   ┌─────────────┐     ┌─────────────┐     ┌─────────────────┐  │
│   │ khlone tui  │     │ dispatch    │     │ repl processes  │  │
│   │             │────►│ queue       │────►│                 │  │
│   │ • instant   │     │             │     │ ┌─────────────┐ │  │
│   │ • filtered  │     │ • persist   │     │ │claude-code  │ │  │
│   │ • attach    │     │ • priority  │     │ │(headless)   │ │  │
│   └─────────────┘     │ • resume    │     │ └─────────────┘ │  │
│         │             └─────────────┘     │ ┌─────────────┐ │  │
│         │                   │             │ │opencode     │ │  │
│         ▼                   │             │ │(headless)   │ │  │
│   ┌─────────────┐           │             │ └─────────────┘ │  │
│   │ output      │◄──────────┘             └─────────────────┘  │
│   │ filter      │                                │              │
│   │             │◄───────────────────────────────┘              │
│   │ • progress  │         raw stream                            │
│   │ • errors    │                                               │
│   │ • summaries │                                               │
│   └─────────────┘                                               │
│                                                                 │
│   STATE (~/.khlone/)                                            │
│   ├── queue.json        # task queue, persists across restarts  │
│   ├── clones/           # clone state and checkpoints           │
│   │   ├── mechanic.1/                                           │
│   │   │   ├── state.json                                        │
│   │   │   ├── checkpoint.json                                   │
│   │   │   └── transcript.jsonl                                  │
│   │   └── mechanic.2/                                           │
│   └── config.json       # khlone config                         │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### components

| component | purpose |
|-----------|---------|
| **khlone tui** | instant-launch interface, 0ms keystrokes |
| **dispatch queue** | persists tasks, survives crashes, manages priority |
| **repl manager** | spawns/restarts repls, feeds tasks, captures output |
| **output filter** | transforms raw stream into progress summaries |
| **checkpoint store** | tracks repl state for crash recovery |
| **transcript archive** | stores full clone output for review |

### headless mode

repls run without their tui — just the ai process:

```sh
# claude-code headless
claude --headless --output-format jsonl

# opencode headless
opencode --no-tui --json
```

benefits:
- **lower resource draw** — no electron/terminal overhead
- **faster startup** — skip ui initialization
- **stable output** — json stream instead of ansi chaos
- **scriptable** — easy to parse and filter

### attach mode

when you `khlone attach`, khlone:

1. pauses the output filter
2. connects your terminal directly to repl's pty
3. you see raw repl output, can type directly
4. `ctrl+d` detaches, resumes filtered mode

```
normal mode:    you ──► khlone tui ──► filter ──► repl (headless)
attach mode:    you ──────────────────────────► repl (headful)
```

---

## mental model

### how you'd describe khlone to a friend

> "khlone is like a buffer between me and claude code. i type my tasks instantly — they queue up. claude code runs in the background, headless, so my laptop doesn't melt. i see filtered progress instead of walls of text. if claude code crashes, khlone restarts it and keeps my queue. i can drop into the raw session anytime with `attach`."

### analogies

| analogy | fit |
|---------|-----|
| **print spooler** | queue tasks, they execute in order, survive app crashes |
| **tmux for ai** | session persists, attach/detach freely, survives disconnects |
| **email outbox** | write messages offline, they send when ready |
| **job queue** | dispatch work, check status, manage priority |

### terms

| user might say | khlone term |
|----------------|-------------|
| "run this task" | `khlone dispatch "..."` |
| "what's it up to" | `khlone status` / `khlone watch` |
| "queue more work" | `khlone dispatch "..."` (stacks) |
| "show me the raw output" | `khlone attach` |
| "go back to summary" | `ctrl+d` (detach) |
| "what's in the queue" | `khlone queue` |
| "do this next" | `khlone dispatch "..." --priority` |
| "cancel that task" | `khlone queue rm N` |
| "it crashed" | (khlone auto-recovers, you may not notice) |

---

## evaluation

### how well does it solve the goals?

| goal | solved? |
|------|---------|
| input latency eliminated | yes — khlone tui is instant, queue accepts immediately |
| resource consumption reduced | yes — headless mode, no electron/tui overhead |
| survive crashes | yes — queue persists, checkpoint enables resume |
| work while repl is busy | yes — queue stacks tasks, execute in order |
| see progress without noise | yes — output filter shows summaries |
| access raw repl when needed | yes — attach mode gives direct access |

### pros

| benefit | details |
|---------|---------|
| instant input | 0ms keystroke latency — it's just a local tui |
| queue tasks | don't wait for completion to dispatch next |
| crash recovery | auto-restart, resume from checkpoint |
| headless efficiency | repls run without ui overhead |
| filtered output | progress summaries instead of log spam |
| attach anytime | drop into raw session when needed |
| transcript archive | review what happened, token account |
| no zone required | works locally, no provision needed |

### cons / edgecases

| edgecase | mitigation |
|----------|------------|
| checkpoint accuracy | conservative checkpoints, may redo some work |
| headless mode support | not all repls support it — fallback to hidden window |
| output filter quality | start simple (progress %), improve over time |
| multiple clone resource use | still runs multiple repls — but headless helps |
| repl api stability | repls may change their cli — abstract via adapters |

### cost comparison

| approach | resource draw | stability | input latency |
|----------|---------------|-----------|---------------|
| raw claude-code | high (electron + node) | low (crashes often) | high (ui blocks) |
| khlone replbuffer | low (headless + filter) | high (auto-recovery) | 0ms (instant queue) |

replbuffer mode costs no extra — same tokens, same compute, just better ux.

---

## this as the first anchor?

replbuffer could be v0.0 — before zones:

```
v0.0: replbuffer        ← LOCAL ONLY (no zones yet)
  │   • dispatch queue
  │   • headless repls
  │   • crash recovery
  │   • attach/detach
  │   • output filter
  │
v0.1: zone bootstrap    ← REMOTE (provision + sync + shell)
  │
v0.2: single clone      ← REMOTE (spawn + attach)
  │
...
```

**why anchor here?**

1. **no infrastructure** — works locally, no ec2, no provision
2. **immediate value** — solves daily pain (crashes, latency, resource hog)
3. **foundation for zones** — same tui, queue, attach model extends to remote
4. **low risk** — can ship fast, iterate on ux before infra complexity
5. **proves the model** — if local replbuffer works, remote zones are just "same model, but over there"

**what it fleshes out:**

- khlone tui architecture
- dispatch queue design
- output filter approach
- attach/detach semantics
- transcript storage
- crash recovery model

all of these apply directly to zone mode later.

---

## open questions

1. **checkpoint granularity**: how often to checkpoint? per tool call? per file write?
   - tradeoff: more checkpoints = better recovery, but more overhead

2. **headless mode availability**: which repls support headless?
   - claude-code: unclear, may need `--pipe` mode or hidden window
   - opencode: likely supports it
   - fallback: run in hidden terminal, capture pty output

3. **output filter design**: what to show in filtered mode?
   - option a: just progress % and current file
   - option b: progress + recent tool calls + errors
   - option c: configurable verbosity levels

4. **queue persistence**: where to store queue?
   - option a: ~/.khlone/queue.json (simple, local)
   - option b: sqlite (better for complex queries)
   - option c: per-worktree queue (isolate by project)

5. **multi-clone resource limits**: how many local clones is too many?
   - depends on headless efficiency
   - may need `khlone config set max-local-clones 3`

6. **repl adapter interface**: how to abstract different repls?
   - need: spawn, send task, read output, checkpoint, restart
   - each repl (claude-code, opencode, aider) gets an adapter

7. **attach semantics**: what happens to queue when attached?
   - option a: queue pauses, you drive manually
   - option b: queue continues, you observe
   - option c: configurable per-attach

---

## command reference (replbuffer mode)

```sh
# launch khlone tui
khlone

# dispatch tasks
khlone dispatch "TASK"              # queue task to default clone
khlone dispatch "TASK" --to CLONE   # queue to specific clone
khlone dispatch "TASK" --priority   # queue at front (after current)

# status
khlone status                       # current clone status
khlone watch                        # live filtered progress

# queue management
khlone queue                        # list queue
khlone queue rm N                   # remove task N
khlone queue clear                  # clear queued (keep current)
khlone queue pause                  # pause after current
khlone queue resume                 # resume queue

# attach/detach
khlone attach [CLONE]               # drop into raw repl session
# ctrl+d                            # detach back to filtered

# crew (local clones)
khlone crew                         # list local clones
khlone crew add --role ROLE --brain BRAIN
khlone crew del CLONE

# transcripts
khlone log                          # current session
khlone log --clone CLONE            # specific clone
khlone log --search "QUERY"         # search transcripts

# config
khlone config set default-brain claude
khlone config set max-local-clones 3
khlone config set headless true
```

---

## next steps

1. prototype khlone tui (dispatch, status, queue display)
2. implement dispatch queue with persistence
3. research headless mode for claude-code
4. build repl adapter for claude-code
5. implement basic output filter
6. add attach/detach mode
7. add crash detection + auto-restart
8. add checkpoint/resume logic
9. add transcript storage
10. then: extend to zones (same model, remote execution)
